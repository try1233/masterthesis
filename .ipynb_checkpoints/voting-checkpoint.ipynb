{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"device\": \"cuda\",\n",
    "    \"datatype\": \"images\",\n",
    "    \"dataset_path\": \"../data/images/\",\n",
    "\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    \"dataset_mean\": [0.4914, 0.4822, 0.4465],\n",
    "    \"dataset_std\": [0.2023, 0.1994, 0.2010],\n",
    "\n",
    "    # model\n",
    "    \"arch\": \"ResNet18\",\n",
    "    \"protected\": True,\n",
    "    \"in_channels\": 4,\n",
    "    \"out_channels\": 10,\n",
    "\n",
    "    # training\n",
    "    \"batch_size_training\": 128,\n",
    "    \"batch_size_inference\": 300,\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"max_epochs\": 400,\n",
    "    \"early_stopping\": 400,\n",
    "    \"lr_scheduler\": \"cosine\",\n",
    "    \"logging\": True,\n",
    "\n",
    "    \"alpha\": 0.01,\n",
    "    \"n0\": 1_000,\n",
    "    \"n1\": 10_000,\n",
    "\n",
    "    \"smoothing_config\" : {\n",
    "        \"smoothing_distribution\": \"ablation_smoothing\",\n",
    "        \"append_indicator\": True,\n",
    "        \"k\": 150,\n",
    "        \"std\": 1,\n",
    "        \"d\": 1024\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sparse_smoothing.utils import sparse_perturb\n",
    "import torch.nn as nn\n",
    "from models import *\n",
    "\n",
    "\n",
    "\n",
    "def smooth_image_classifier(hparams, model, data, n_samples,\n",
    "                            progress_bar=True):\n",
    "    \"\"\" Computes the prediction of the smoothed classifier by\n",
    "        sampling images from the smoothing distribution and classifying\n",
    "        all images using the model.\n",
    "\n",
    "    Args:\n",
    "        hparams (dict): Experiment hyperparameters.\n",
    "        model (nn.Module): Image classifier.\n",
    "        data (torch.utils.data.Dataset): Image classification dataset.\n",
    "        n_samples (int): Number of Monte Carlo samples (images) to sample.\n",
    "        progress_bar (bool, optional): Whether you want a progress bar.\n",
    "          Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Votes per class for each node, and ground truth targets.\n",
    "    \"\"\"\n",
    "    nc = 10\n",
    "    votes = torch.zeros(len(data), nc, dtype=torch.int32)\n",
    "    test_loader = torch.utils.data.DataLoader(data,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=1)\n",
    "\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(tqdm(test_loader)):\n",
    "            input = input.squeeze().to(\"cuda\")\n",
    "            targets.append(target)\n",
    "\n",
    "            batch_sizes = [300] * \\\n",
    "                int(n_samples/300)\n",
    "            if sum(batch_sizes) < n_samples:\n",
    "                batch_sizes.append(n_samples - sum(batch_sizes))\n",
    "\n",
    "            for batch_size in batch_sizes:\n",
    "                x = smooth_image(input.clone(), hparams, batch_size=batch_size)\n",
    "                predictions = model(x).argmax(1).cpu()\n",
    "                votes[i] += F.one_hot(predictions, int(nc)).sum(0)\n",
    "    return votes, targets\n",
    "\n",
    "\n",
    "def smooth_image(x, hparams, batch_size=1):\n",
    "    \"\"\"Samples images from the smoothing distribution around x.\n",
    "\n",
    "    Args:\n",
    "        x (torch.tensor): Image data (shape: channels, width, height).\n",
    "        hparams (dict): Experiment hyperparameters.\n",
    "        batch_size (int, optional): Number of images to sample. Defaults to 1.\n",
    "    \"\"\"\n",
    "    smoothing_config = hparams['smoothing_config']\n",
    "    smoothing_distribution = smoothing_config[\"smoothing_distribution\"]\n",
    "    normalize = NormalizeLayer(hparams[\"dataset_mean\"], hparams[\"dataset_std\"])\n",
    "\n",
    "    (num_channels, height, width) = x.shape\n",
    "\n",
    "    if smoothing_distribution == \"ablation_levine\":\n",
    "        k = smoothing_config[\"k\"]\n",
    "        d = smoothing_config[\"d\"]\n",
    "        # first normalize, then ablate\n",
    "        x = normalize(x, batched=False)\n",
    "        x = torch.cat([x, 1-x])\n",
    "\n",
    "        batched_x = []\n",
    "        for _ in range(batch_size):\n",
    "            ablate = np.random.choice(np.arange(d), d-k, replace=False)\n",
    "            ablated_x = x.clone()\n",
    "            ablated_x.reshape(num_channels*2, -1)[:, ablate] = 0\n",
    "            batched_x.append(ablated_x)\n",
    "        x = torch.stack(batched_x)\n",
    "    elif smoothing_distribution == \"ablation_smoothing\":\n",
    "        block_size = 15\n",
    "        std = 1\n",
    "        x = x.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "        x = random_mask_batch_one_sample_ablation_no_noise(x, block_size, sigma = std, normalizer = normalize)\n",
    "        #x = normalize(x, batched=True)\n",
    "    elif smoothing_distribution == \"gaussian\":\n",
    "        std = smoothing_config[\"std\"]\n",
    "        x = x.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "        x = add_full_gaussian_noise(x, std)\n",
    "        x = normalize(x, batched=True)  # first add noise then normalize\n",
    "\n",
    "    elif smoothing_distribution == \"hierarchical_gaussian\":\n",
    "        append_indicator = smoothing_config[\"append_indicator\"]\n",
    "        std = smoothing_config[\"std\"]\n",
    "        k = smoothing_config[\"k\"]\n",
    "        d = smoothing_config[\"d\"]\n",
    "        p = 1-k/d\n",
    "\n",
    "        indicator = np.random.binomial(1, p, batch_size*d)\n",
    "        i = torch.tensor(indicator, device=x.device).reshape(\n",
    "            batch_size, 1, width, height)\n",
    "\n",
    "        x = x.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "        noised_data = add_full_gaussian_noise(x[torch.where(i)[0],\n",
    "                                                :,\n",
    "                                                torch.where(i)[2],\n",
    "                                                torch.where(i)[3]], std)\n",
    "        x[torch.where(i)[0], :, torch.where(i)[2],\n",
    "          torch.where(i)[3]] = noised_data\n",
    "        x = normalize(x, batched=True)  # first add noise then normalize\n",
    "\n",
    "        if append_indicator:\n",
    "            x = torch.cat((x, i), dim=1)\n",
    "\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def add_full_gaussian_noise(X, std):\n",
    "    return X + std * torch.randn(X.shape).to(X.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from models import ResNet18, ResNet50\n",
    "from training import load_image_dataset \n",
    "train_data, short_train_data, short_test_data, test_data = load_image_dataset(\"CIFAR10\", './../data')\n",
    "\n",
    "net = ResNet18()\n",
    "checkpoint_file_path = \"/nfs/homedirs/scle/src/my-project/seml/examples/tutorial/master_thesis/master_thesis/checkpoints/resnet18_88acc.pth\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_file_path)\n",
    "\n",
    "# Wrap the model with DataParallel during loading\n",
    "net = torch.nn.DataParallel(net)\n",
    "\n",
    "# Load the model's state dictionary from the loaded checkpoint\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "# Access other information if needed\n",
    "accuracy = checkpoint['acc']\n",
    "epoch = checkpoint['epoch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c857b64e530437ab71e8167906d813a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m votes, targets \u001b[38;5;241m=\u001b[39m \u001b[43msmooth_image_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 48\u001b[0m, in \u001b[0;36msmooth_image_classifier\u001b[0;34m(hparams, model, data, n_samples, progress_bar)\u001b[0m\n\u001b[1;32m     45\u001b[0m     batch_sizes\u001b[38;5;241m.\u001b[39mappend(n_samples \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(batch_sizes))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m batch_sizes:\n\u001b[0;32m---> 48\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43msmooth_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model(x)\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     50\u001b[0m     votes[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(predictions, \u001b[38;5;28mint\u001b[39m(nc))\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 87\u001b[0m, in \u001b[0;36msmooth_image\u001b[0;34m(x, hparams, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     86\u001b[0m     x \u001b[38;5;241m=\u001b[39m random_mask_batch_one_sample_ablation_no_noise(x, block_size, sigma \u001b[38;5;241m=\u001b[39m std)\n\u001b[0;32m---> 87\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m smoothing_distribution \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     89\u001b[0m     std \u001b[38;5;241m=\u001b[39m smoothing_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/src/my-project/seml/examples/tutorial/master_thesis/models.py:767\u001b[0m, in \u001b[0;36mNormalizeLayer.forward\u001b[0;34m(self, input, batched)\u001b[0m\n\u001b[1;32m    764\u001b[0m     means \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans\u001b[38;5;241m.\u001b[39mrepeat((height, width, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    765\u001b[0m     stds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstds\u001b[38;5;241m.\u001b[39mrepeat((height, width, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m/\u001b[39m stds\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "votes, targets = smooth_image_classifier(hparams, net, test_data, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/scle/src/my-project/seml/examples/tutorial/master_thesis\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcifar_one_block__regularization_0.0005_model_resnet18_block_15_epoch_{}.pth\u001b[0m/\n",
      "ckpt_epoch_30.pth\n",
      "resnet18_88acc.pth\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
